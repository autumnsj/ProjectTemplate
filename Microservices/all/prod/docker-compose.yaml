version: "3.8"
services:
  nacos:
    image: nacos/nacos-server:${NACOS_VERSION}
    container_name: nacos
    volumes:
      - ./volumes/nacos/:/home/nacos/logs
      - ./config/nacos/application.properties:/home/nacos/conf/application.properties
    hostname: nacos
    environment:
      - TZ=Asia/Shanghai
      - PREFER_HOST_MODE=hostname
      - MODE=standalone
      - SPRING_DATASOURCE_PLATFORM=mysql
      - NACOS_AUTH_IDENTITY_KEY=2222
      - NACOS_AUTH_IDENTITY_VALUE=2xxx
      - NACOS_AUTH_TOKEN=SecretKey012345678901234567890123456789012345678901234567890123456789
      - MYSQL_SERVICE_PASSWORD=${MYSQL_ROOT_PASSWORD}
      - JAVA_OPTS=-Ddb.password.0=${MYSQL_ROOT_PASSWORD}
    ports:
      - "8848:8848"
      - "9848:9848"
    healthcheck:
      test: ["CMD-SHELL", "echo 'ruok' | curl -s telnet://localhost:8848 || exit 1"]
      retries: 10
    restart: on-failure
    depends_on:
      mysql:
        condition: service_healthy
    networks:
      prod_net:
    deploy:
      placement:
        constraints:
          - node.role == manager
  mysql:
    image: mysql:5.7.40
    container_name: mysql
    environment:
      - TZ=Asia/Shanghai
      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}
      - MYSQL_DATABASE=nacos
      - MYSQL_USER=nacos
      - MYSQL_PASSWORD=${MYSQL_NACOS_PASSWORD}
      - LANG=C.UTF-8
    volumes:
      - ./volumes/mysql:/var/lib/mysql
      - ./config/mysql:/docker-entrypoint-initdb.d
    ports:
      - "3306:3306"
    healthcheck:
      test: [ "CMD", "mysqladmin" ,"ping", "-h", "localhost" ]
      interval: 5s
      timeout: 10s
      retries: 10
    deploy:
      placement:
        constraints:
          - node.role == manager
  redis:
    container_name: redis
    image: redis
    restart: always
    ports:
      - '6379:6379'
    #command: redis-server --save 20 1 --loglevel warning --requirepass eYVX7EwVmmxKPCDmwMtyKVge8oLd2t81
    environment:
      - TZ=Asia/Shanghai
      - REDIS_HOST_PASSWORD=${REDIS_PASSWORD}
    volumes: 
      - "./volumes/redis:/data"
    networks:
      prod_net:
    deploy:
      placement:
        constraints:
          - node.role == manager
  seata:
    container_name: seata
    image: seataio/seata-server
    # ports:
    #   - "7091:7091"
    #   - "8091:8091"
    environment:
      - TZ=Asia/Shanghai
      # 注册到nacos的服务的ip
      - SEATA_IP=${LOCAL_IP} 
      - SEATA_PORT=8091
      - JAVA_OPTS=-Dconsole.user.password=${SEATA_PASSWORD} -Dseata.config.nacos.password=${NACOS_PASSWORD} -Dseata.registry.nacos.password=${NACOS_PASSWORD}
    volumes:
      #- "/usr/share/zoneinfo/Asia/Shanghai:/etc/localtime"        #设置系统时区
      #- "/usr/share/zoneinfo/Asia/Shanghai:/etc/timezone"  #设置时区
      # 假设我们通过docker cp命令把资源文件拷贝到相对路径`./seata-server/resources`中
      # 如有问题，请阅读上面的[注意事项]以及[使用自定义配置文件]
      - "./config/seata/application.yml:/seata-server/resources/application.yml"
      #- "./config/seata/application.yml:/seata-server/conf/application.yml"
    depends_on:
      nacos:
        condition: service_healthy
      mysql:
        condition: service_healthy 
    networks:
      prod_net:
    deploy:
      placement:
        constraints:
          - node.role == manager
  # rabbitmq:
  #   image: rabbitmq:management
  #   container_name: rabbitmq
  #   restart: always
  #   ports:
  #     - 5672:5672
  #     - 15672:15672
  #   environment:
  #     RABBITMQ_DEFAULT_VHOST: '/'
  #     RABBITMQ_DEFAULT_USER: admin
  #     RABBITMQ_DEFAULT_PASS: admin
  # rocketmq-namesrv:
  #   image: apache/rocketmq
  #   container_name: rocketmq-namesrv
  #   environment:
  #     - JAVA_OPT_EXT=-server -Xms128m -Xmx128m
  #   ports:
  #     - 9876:9876
  #   volumes:
  #     - ./volumes/mq/namesrv/logs:/home/rocketmq/logs
  #   command: sh mqnamesrv
  #   networks:
  #     prod_net:
  #Service for broker
  rocketmq-broker:
    image: apache/rocketmq
    container_name: rocketmq-broker
    user: root
    # ports:
    #   - 10909:10909
    #   - 10911:10911
    #   - 10912:10912
    environment:
      - NAMESRV_ADDR=rocketmq-namesrv:9876
      - JAVA_OPT_EXT=-server -Xms128m -Xmx128m
    volumes:
      - ./volumes/mq/broker/logs:/home/rocketmq/logs
      - ./volumes/mq/broker/store:/home/rocketmq/store
      - ./config/rocketmq/broker-a.conf:/opt/rocketmq-ROCKETMQ_VERSION/conf/tmp.conf
    command: >
      sh -c "cp /opt/rocketmq-ROCKETMQ_VERSION/conf/tmp.conf /opt/rocketmq-ROCKETMQ_VERSION/conf/broker.conf && \
             echo 'brokerIP1=${LOCAL_IP}' >> /opt/rocketmq-ROCKETMQ_VERSION/conf/broker.conf && \
             sh mqbroker -c /opt/rocketmq-ROCKETMQ_VERSION/conf/broker.conf"
    networks:
      prod_net:
    deploy:
      placement:
        constraints:
          - node.role == manager
  rocketmq-console:
    image: styletang/rocketmq-console-ng
    container_name: rocketmq-console
    ports:
      - 8081:8080
    environment:
      JAVA_OPTS: -Drocketmq.namesrv.addr=rocketmq-namesrv:9876 -Dcom.rocketmq.sendMessageWithVIPChannel=false -Drocketmq.config.loginRequired=true -Drocketmq.config.adminPassword=${ROCKETMQ_PASSWORD}
    networks:
      prod_net:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch-oss:${ES_VERSION}
    container_name: elasticsearch
    mem_limit: 1g
    # ports:
    #   - "9200:9200"
    healthcheck:
      test: [ "CMD-SHELL", "curl --silent --fail localhost:9200/_cluster/health || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ulimits:
      memlock:
        soft: -1
        hard: -1
    networks:
      prod_net:
    deploy:
      placement:
        constraints:
          - node.role == manager
  skywalking-oap:
    image: ${OAP_IMAGE}
    container_name: skywalking-oap
    depends_on:
      elasticsearch:
        condition: service_healthy
    # ports:
    #   - "11800:11800"
    #   - "12800:12800"
    healthcheck:
      test: [ "CMD-SHELL", "/skywalking/bin/swctl ch" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    environment:
      SW_STORAGE: elasticsearch
      SW_STORAGE_ES_CLUSTER_NODES: elasticsearch:9200
      SW_HEALTH_CHECKER: default
      SW_TELEMETRY: prometheus
      JAVA_OPTS: "-Xms512m -Xmx512m"
    networks:
      prod_net:
    deploy:
      placement:
        constraints:
          - node.role == manager
  skywalking-ui:
    image: ${UI_IMAGE}
    container_name: skywalking-ui
    depends_on:
      skywalking-oap:
        condition: service_healthy
    ports:
      - "8082:8080"
    environment:
      - SW_OAP_ADDRESS=http://skywalking-oap:12800
      - SW_ZIPKIN_ADDRESS=http://skywalking-oap:9412
      - JAVA_OPTS=Dsecurity.user.admin.password=${SKYWALKING_PASSWORD}
    networks:
      prod_net:
    deploy:
      placement:
        constraints:
          - node.role == manager
  sentinel:
    container_name: sentinel
    build:
      context: ../../sentinel
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
    environment:
      JAVA_OPTIONS: -Dnacos.addr=nacos:8848 -Dauth.password=${SENTINEL_PASSWORD}
    depends_on:
      nacos:
        condition: service_healthy
    networks:
      prod_net:
    deploy:
      placement:
        constraints:
          - node.role == manager
  xxl-job:
    image: xuxueli/xxl-job-admin:2.0.2
    restart: always
    container_name: xxl-job
    ports:
      - 28888:8080
    volumes:
      - "./volumes/xxl-job:/data/applogs"
    environment:
      #- server.servlet.context-path=/xxl-job-admin
      - spring.datasource.url=jdbc:mysql://mysql:3306/xxl-job?Unicode=true&characterEncoding=UTF-8&autoReconnect=true
      - spring.datasource.password=${MYSQL_ROOT_PASSWORD}
      - spring.datasource.username=root
    networks:
      prod_net:
    deploy:
      placement:
        constraints:
          - node.role == manager
networks:
  prod_net:
    external: true