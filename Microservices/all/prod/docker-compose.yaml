version: "3.8"
services:
  mysql:
      image: mysql:5.7.40
      environment:
        - TZ=Asia/Shanghai
        - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}
        - MYSQL_DATABASE=nacos
        - MYSQL_USER=nacos
        - MYSQL_PASSWORD=${MYSQL_NACOS_PASSWORD}
        - LANG=C.UTF-8
      volumes:
        - ./volumes/mysql:/var/lib/mysql
        - ./config/mysql:/docker-entrypoint-initdb.d
      ports:
        - "3306:3306"
      healthcheck:
        test: [ "CMD", "mysqladmin" ,"ping", "-h", "localhost" ]
        interval: 5s
        timeout: 10s
        retries: 10
      networks:
        prod_net:
      # deploy:
      #   placement:
      #     constraints:
      #       - node.role == manager
  nacos:
    image: ${NACOS_VERSION}
    volumes:
      - ./volumes/nacos/:/home/nacos/logs
      - ./config/nacos/application.properties:/home/nacos/conf/application.properties
    hostname: nacos
    environment:
      - TZ=Asia/Shanghai
      - PREFER_HOST_MODE=hostname
      - MODE=standalone
      - SPRING_DATASOURCE_PLATFORM=mysql
      - NACOS_AUTH_IDENTITY_KEY=2222
      - NACOS_AUTH_IDENTITY_VALUE=2xxx
      - NACOS_AUTH_TOKEN=SecretKey012345678901234567890123456789012345678901234567890123456789
      - JVM_XMS=256m
      - JVM_XMX=256m
      - MYSQL_PASSWORD=${MYSQL_NACOS_PASSWORD}
    ports:
      - "8848:8848"
      - "9848:9848"
    healthcheck:
      test: ["CMD-SHELL", "echo 'ruok' | curl -s telnet://localhost:8848 || exit 1"]
      retries: 10
    networks:
      - prod_net
    # deploy:
    #   placement:
    #     constraints:
    #       - node.role == manager
    depends_on:
      mysql:
        condition: service_healthy
  redis:
    image: redis
    ports:
      - '6379:6379'
    #command: redis-server --save 20 1 --loglevel warning --requirepass eYVX7EwVmmxKPCDmwMtyKVge8oLd2t81
    environment:
      - TZ=Asia/Shanghai
      - REDIS_HOST_PASSWORD=${REDIS_PASSWORD}
    volumes: 
      - "./volumes/redis:/data"
    networks:
      prod_net:
    # deploy:
    #   placement:
    #     constraints:
    #       - node.role == manager
  seata:
    image: seataio/seata-server
    ports:
      - "7091:7091"
      - "8091:8091"
    environment:
      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}
      - SEATA_PASSWORD=${SEATA_PASSWORD}
      - NACOS_PASSWORD=${NACOS_PASSWORD}
      - TZ=Asia/Shanghai
      # 注册到nacos的服务的ip
      - SEATA_IP=seata 
      - SEATA_PORT=8091
      - spring.cloud.inetutils.ignoredInterfaces=eth1.*,*lo.*
      - spring.cloud.inetutils.preferredNetworks=10.0
      - JAVA_OPTS=-Dspring.cloud.inetutils.ignoredInterfaces=eth1.*,*lo.*
    volumes:
      #- "/usr/share/zoneinfo/Asia/Shanghai:/etc/localtime"        #设置系统时区
      #- "/usr/share/zoneinfo/Asia/Shanghai:/etc/timezone"  #设置时区
      # 假设我们通过docker cp命令把资源文件拷贝到相对路径`./seata-server/resources`中
      # 如有问题，请阅读上面的[注意事项]以及[使用自定义配置文件]
      - "./config/seata/application.yml:/seata-server/resources/application.yml"
      #- "./config/seata/application.yml:/seata-server/conf/application.yml"
    networks:
      prod_net:
    # deploy:
    #   placement:
    #     constraints:
    #       - node.role == manager
    depends_on:
      nacos:
        condition: service_healthy
  # rabbitmq:
  #   image: rabbitmq:management
  #   ports:
  #     - 5672:5672
  #     - 15672:15672
  #   environment:
  #     RABBITMQ_DEFAULT_VHOST: '/'
  #     RABBITMQ_DEFAULT_USER: admin
  #     RABBITMQ_DEFAULT_PASS: admin
  rocketmq-namesrv:
    image: apache/rocketmq
    environment:
      - JAVA_OPT_EXT=-server -Xms128m -Xmx128m
    ports:
      - 9876:9876
    volumes:
      - ./volumes/mq/namesrv/logs:/home/rocketmq/logs
    command: sh mqnamesrv
    networks:
      prod_net:
    # deploy:
    #   placement:
    #     constraints:
    #       - node.role == manager
  #Service for broker
  rocketmq-broker:
    image: apache/rocketmq
    user: root
    ports:
      - 10909:10909
      - 10911:10911
      - 10912:10912
    environment:
      - NAMESRV_ADDR=rocketmq-namesrv:9876
      - JAVA_OPT_EXT=-server -Xms128m -Xmx128m
    volumes:
      - ./volumes/mq/broker/logs:/home/rocketmq/logs
      - ./volumes/mq/broker/store:/home/rocketmq/store
      - ./config/rocketmq/broker-a.conf:/opt/rocketmq-ROCKETMQ_VERSION/conf/tmp.conf
    command: >
      sh -c "cp /opt/rocketmq-ROCKETMQ_VERSION/conf/tmp.conf /opt/rocketmq-ROCKETMQ_VERSION/conf/broker.conf && \
             echo 'brokerIP1=${LOCAL_IP}' >> /opt/rocketmq-ROCKETMQ_VERSION/conf/broker.conf && \
             sh mqbroker -c /opt/rocketmq-ROCKETMQ_VERSION/conf/broker.conf"
    networks:
      prod_net:
    # deploy:
    #   placement:
    #     constraints:
    #       node.role == manager
  rocketmq-console:
    image: styletang/rocketmq-console-ng
    ports:
      - 8081:8080
    environment:
      JAVA_OPTS: -Drocketmq.namesrv.addr=rocketmq-namesrv:9876 -Dcom.rocketmq.sendMessageWithVIPChannel=false -Drocketmq.config.loginRequired=true -Drocketmq.config.adminPassword=${ROCKETMQ_PASSWORD}
    networks:
      prod_net:
  elasticsearch:
    image: ${ES_VERSION}
    ports:
      - "9200:9200"
    healthcheck:
      test: [ "CMD-SHELL", "curl --silent --fail localhost:9200/_cluster/health || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ulimits:
      memlock:
        soft: -1
        hard: -1
    networks:
      prod_net:
    # deploy:
    #   resources:
    #     limits:
    #       memory: 700m
    #   placement:
    #     constraints:
    #       - node.role == manager
  skywalking-oap:
    image: ${OAP_IMAGE}
    depends_on:
      elasticsearch:
        condition:
          service_healthy
    # ports:
    #   - "11800:11800"
    #   - "12800:12800"
    healthcheck:
      test: [ "CMD-SHELL", "/skywalking/bin/swctl ch" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    environment:
      SW_STORAGE: elasticsearch
      SW_STORAGE_ES_CLUSTER_NODES: elasticsearch:9200
      SW_HEALTH_CHECKER: default
      SW_TELEMETRY: prometheus
      JAVA_OPTS: "-Xms512m -Xmx512m"
    networks:
      prod_net:
    # deploy:
    #   placement:
    #     constraints:
    #       - node.role == manager
  skywalking-ui:
    image: ${UI_IMAGE}
    ports:
      - "8082:8080"
    environment:
      - SW_OAP_ADDRESS=http://skywalking-oap:12800
      - SW_ZIPKIN_ADDRESS=http://skywalking-oap:9412
      #- JAVA_OPTS=Dsecurity.user.admin.password=${SKYWALKING_PASSWORD}
    networks:
      prod_net:
    # deploy:
    #   placement:
    #     constraints:
    #       - node.role == manager
    depends_on:
      skywalking-oap:
        condition:
          service_healthy
  sentinel:
    image: ${SENTINEL_IMAGE}
    ports:
      - "8080:8080"
    environment:
      JAVA_OPTIONS: -Dnacos.addr=nacos:8848 -Dnacos.username=nacos -Dnacos.password=${NACOS_PASSWORD} -Dauth.password=${SENTINEL_PASSWORD}
    networks:
      prod_net:
    # deploy:
    #   placement:
    #     constraints:
    #       - node.role == manager
    depends_on:
      nacos:
        condition:
          service_healthy
  xxl-job:
    image: xuxueli/xxl-job-admin:2.0.2
    ports:
      - 28888:8080
    volumes:
      - "./volumes/xxl-job:/data/applogs"
    environment:
      #- server.servlet.context-path=/xxl-job-admin
      - spring.datasource.url=jdbc:mysql://mysql:3306/xxl-job?Unicode=true&characterEncoding=UTF-8&autoReconnect=true
      - spring.datasource.password=${MYSQL_ROOT_PASSWORD}
      - spring.datasource.username=root
    networks:
      - prod_net
    # deploy:
    #   placement:
    #     constraints:
    #       - node.role == manager
networks:
  prod_net:
    driver: overlay
    external: true
    attachable: true